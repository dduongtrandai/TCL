{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from E:\\Dataset\\EEG\\BCI IV\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daidu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>November 08, 2004  12:00:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>22 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>A04T.gdf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:40:04 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawGDF | A04T.gdf, 22 x 600915 (2403.7 s), ~26 kB, data not loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw=mne.io.read_raw_gdf('E:\\Dataset\\EEG\\BCI IV\\BCICIV_2a_gdf\\A04T.gdf',\n",
    "                         eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Annotations | 610 segments: 1023 (26), 1072 (1), 32766 (7), 768 (288), ...>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1023': 1,\n",
       " '1072': 2,\n",
       " '32766': 3,\n",
       " '768': 4,\n",
       " '769': 5,\n",
       " '770': 6,\n",
       " '771': 7,\n",
       " '772': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events=mne.events_from_annotations(raw)\n",
    "events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>November 08, 2004  12:00:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>22 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>A04T.gdf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:40:04 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawGDF | A04T.gdf, 22 x 600915 (2403.7 s), ~26 kB, data not loaded>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 600915)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From e:\\Code\\TCL\\tcl\\tcl.py:190: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "make savefolder: ./storage/temp...\n",
      "Generating source...\n",
      "Generating sensor signal...\n",
      "    cond thresh: 36.190674\n",
      "    L4: cond=303.126314\n",
      "    L4: cond=56.555460\n",
      "    L4: cond=171.889794\n",
      "    L4: cond=61.038865\n",
      "    L4: cond=40.923516\n",
      "    L4: cond=31.955147\n",
      "    L3: cond=166.553445\n",
      "    L3: cond=46.538361\n",
      "    L3: cond=413.509699\n",
      "    L3: cond=102.349694\n",
      "    L3: cond=470.571844\n",
      "    L3: cond=57.997376\n",
      "    L3: cond=31.264658\n",
      "    L2: cond=91.444432\n",
      "    L2: cond=60.877266\n",
      "    L2: cond=35.757592\n",
      "    L1: cond=60.887093\n",
      "    L1: cond=87.427231\n",
      "    L1: cond=45.493049\n",
      "    L1: cond=166.029907\n",
      "    L1: cond=29.062968\n",
      "    L0: cond=58.152693\n",
      "    L0: cond=81.768960\n",
      "    L0: cond=42.139281\n",
      "    L0: cond=89.550405\n",
      "    L0: cond=62.517179\n",
      "    L0: cond=331.682468\n",
      "    L0: cond=60.373177\n",
      "    L0: cond=22.563836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from subfunc.generate_artificial_data import generate_artificial_data\n",
    "from subfunc.preprocessing import pca\n",
    "from tcl.tcl_train import train\n",
    "\n",
    "\n",
    "# Parameters ==================================================\n",
    "# =============================================================\n",
    "\n",
    "# Data generation ---------------------------------------------\n",
    "random_seed = 0 # random seed\n",
    "num_comp = 20 # number of components (dimension)\n",
    "num_segment = 256 # number of segments\n",
    "num_segmentdata = 512 # number of data-points in each segment\n",
    "num_layer = 5 # number of layers of mixing-MLP\n",
    "\n",
    "# MLP ---------------------------------------------------------\n",
    "list_hidden_nodes = [40, 40, 40, 40, 20]\n",
    "# list of the number of nodes of each hidden layer of feature-MLP\n",
    "# [layer1, layer2, ..., layer(num_layer)]\n",
    "\n",
    "# Training ----------------------------------------------------\n",
    "initial_learning_rate = 0.01 # initial learning rate\n",
    "momentum = 0.9 # momentum parameter of SGD\n",
    "max_steps = int(7e5) # number of iterations (mini-batches)\n",
    "decay_steps = int(5e5) # decay steps (tf.train.exponential_decay)\n",
    "decay_factor = 0.1 # decay factor (tf.train.exponential_decay)\n",
    "batch_size = 512 # mini-batch size\n",
    "moving_average_decay = 0.999 # moving average decay of variables to be saved\n",
    "checkpoint_steps = 1e5 # interval to save checkpoint\n",
    "\n",
    "# for MLR initialization\n",
    "max_steps_init = int(7e4) # number of iterations (mini-batches) for initializing only MLR\n",
    "decay_steps_init = int(5e4) # decay steps for initializing only MLR\n",
    "\n",
    "# Other -------------------------------------------------------\n",
    "# # Note: save folder must be under ./storage\n",
    "train_dir = './storage/temp' # save directory (Caution!! this folder will be removed at first)\n",
    "saveparmpath = os.path.join(train_dir, 'parm.pkl') # file name to save parameters\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "# Prepare save folder -----------------------------------------\n",
    "if train_dir.find(\"./storage/\") > -1:\n",
    "    if os.path.exists(train_dir):\n",
    "        print(\"delete savefolder: {0:s}...\".format(train_dir))\n",
    "        shutil.rmtree(train_dir)  # Remove folder\n",
    "    print(\"make savefolder: {0:s}...\".format(train_dir))\n",
    "    os.makedirs(train_dir)  # Make folder\n",
    "else:\n",
    "    assert False, \"savefolder looks wrong\"\n",
    "\n",
    "\n",
    "# Generate sensor signal --------------------------------------\n",
    "sensor, source, label = generate_artificial_data(num_comp=num_comp,\n",
    "                                                 num_segment=num_segment,\n",
    "                                                 num_segmentdata=num_segmentdata,\n",
    "                                                 num_layer=num_layer,\n",
    "                                                 random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model -------------------------------------------------\n",
    "train(data,\n",
    "      label,\n",
    "      num_class = num_segment,\n",
    "      list_hidden_nodes = list_hidden_nodes,\n",
    "      initial_learning_rate = initial_learning_rate,\n",
    "      momentum = momentum,\n",
    "      max_steps = max_steps,\n",
    "      decay_steps = decay_steps,\n",
    "      decay_factor = decay_factor,\n",
    "      batch_size = batch_size,\n",
    "      train_dir = train_dir,\n",
    "      checkpoint_steps = checkpoint_steps,\n",
    "      moving_average_decay = moving_average_decay,\n",
    "      load_file=init_model_path,\n",
    "      random_seed = random_seed)\n",
    "\n",
    "\n",
    "# Save parameters necessary for evaluation --------------------\n",
    "model_parm = {'random_seed':random_seed,\n",
    "              'num_comp':num_comp,\n",
    "              'num_segment':num_segment,\n",
    "              'num_segmentdata':num_segmentdata,\n",
    "              'num_layer':num_layer,\n",
    "              'list_hidden_nodes':list_hidden_nodes,\n",
    "              'moving_average_decay':moving_average_decay,\n",
    "              'pca_parm':pca_parm}\n",
    "\n",
    "print(\"Save parameters...\")\n",
    "with open(saveparmpath, 'wb') as f:\n",
    "    pickle.dump(model_parm, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
